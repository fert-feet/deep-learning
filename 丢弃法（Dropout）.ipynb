{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abd476c-8a11-4f13-983e-ae3425131a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6eb5d-5080-4d18-9b85-d270c757fa24",
   "metadata": {},
   "source": [
    "### 实现丢弃函数\n",
    "其中 `dropout` 就是丢弃概率 `p` (以 p 概率丢弃神经元)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c24e56fa-6c31-4f7e-88cd-d1308d7e6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_layer(X, dropout):\n",
    "    assert 0 <= dropout <= 1 # 保证概率值的问题\n",
    "    if dropout == 1:\n",
    "        return torch.zeros_like(X) # 神经元置零\n",
    "    if dropout == 0:\n",
    "        return X # 保持原输出\n",
    "    mask = (torch.rand(X.shape) > dropout).float() # 生成一个和 X 形状相同的随机矩阵，大于 p 的为 1 ，其余为 0，最终 mask 由 0 和 1组成\n",
    "    return mask * X / (1.0 - dropout) # mask 乘以 X，达到去除神经元的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd4039-4cee-4239-aee0-d564336ecb6e",
   "metadata": {},
   "source": [
    "测试一下丢弃函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64527cde-ef9c-4bce-a8f8-2ae188431b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape(2, 8)\n",
    "a = dropout_layer(X, 0.)\n",
    "b = dropout_layer(X, 0.5)\n",
    "c = dropout_layer(X, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61444e6-aedb-4b68-b0d3-3ff5d965ea8c",
   "metadata": {},
   "source": [
    "### 定义感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37585663-89ee-4a0d-bab5-3f52023fff0c",
   "metadata": {},
   "source": [
    "使用 Fashion-MNIST 数据集，定义有两个隐藏层的感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5770a38-ed3a-4af4-93a3-74764d17567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hidden1, num_hidden2 = 784, 10, 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8be03b-398b-47d5-bb91-3217c400d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout1, dropout2 = 0.2, 0.5\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hidden1, num_hidden2, is_training = True):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.training = is_training\n",
    "        self.lin1 = nn.Linear(num_inputs, num_hidden1)\n",
    "        self.lin2 = nn.Linear(num_hidden1, num_hidden2)\n",
    "        self.lin3 = nn.Linear(num_hidden2, num_outputs)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        H1 = self.relu(self.lin1(X.reshape(-1, self.num_inputs)))\n",
    "        if self.training == True:\n",
    "            H1 = dropout_layer(H1, dropout1)\n",
    "        H2 = self.relu(self.lin2(H1))\n",
    "        if self.training == True:\n",
    "            H2 = dropout_layer(H2, dropout2)\n",
    "        out = self.lin3(H2)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
