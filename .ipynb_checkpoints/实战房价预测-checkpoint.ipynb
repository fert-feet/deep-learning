{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1093537a-37e8-434c-9fdd-ecc7c22122ce",
   "metadata": {},
   "source": [
    "### 下载和缓存数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d7b3e0-b014-436c-80e8-12f81747397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27d291-1d0c-4862-b16b-48d78289482b",
   "metadata": {},
   "source": [
    "`download` 函数用于下载 `DATA_HUB` 中对应数据集名字的数据，若已下载过则验证后直接使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeaf5259-a6d0-403d-b1ac-2bbc43f69573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(name, cache_dir=os.path.join('.', 'data')):\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\" # 传入的数据集名字不存在（没有 url 怎么下载？）\n",
    "    url, sha1_hash = DATA_HUB[name] # DATA_HUB 存储数据集对应链接和 sha1 加密数据\n",
    "    full_dir = os.path.join(cache_dir, name.split('_')[1]) # 完整文件前置目录（*/data/数据集名称文件夹/数据集）\n",
    "    os.makedirs(full_dir, exist_ok=True)\n",
    "    fname = os.path.join(full_dir, url.split('/')[-1]) # 数据集完整目录\n",
    "    if os.path.exists(fname): # 如果已经下载过就验证 sha1 是否对应 DATA_HUB 中存储的值\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576) # 读 1MB\n",
    "                if not data: #如果为空（文件读完就结束）\n",
    "                    break\n",
    "                sha1.update(data) # 计算哈希值\n",
    "        if sha1.hexdigest() == sha1_hash: # hexdigest() 返回 sha1 加密的摘要，如果匹配则证明文件对了（已经下载的文件可以用）\n",
    "            return fname\n",
    "    print(f\"从{url}下载{fname}\")\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b6449-4c13-4cf8-8c88-cef56f342581",
   "metadata": {},
   "source": [
    "`download_extract` 函数用于下载并解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11a6326d-2c21-4d14-a389-a4dab6989d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_extract(name, folder=None): # 有问题，folder 没被用到  //TODO\n",
    "    fname = download(name) # fname 是下载数据集的完整目录\n",
    "    base_dir = os.path.dirname(fname) # 拿到前置目录部分（非(文件名+后缀)）\n",
    "    data_dir, ext = os.path.splitext(fname) # 如 [path/to/dir/filename, .exe]\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只能解压zip/tar'\n",
    "    fp.extractall(base_dir) # 解压到同级目录\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437679ca-19ca-4d33-bd6e-b9882b260602",
   "metadata": {},
   "source": [
    "`download_all` 函数可以下载字典里所有数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a2e5e5-55c1-4343-b6d2-3ad69aa5b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all():\n",
    "    for name in DATA_HUB:\n",
    "        download(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef32e1d1-bc6c-4239-94ca-d8937c92d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908227c3-c433-4e98-ba68-2a2c2c801ed8",
   "metadata": {},
   "source": [
    "### 访问和读取数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a4003-716e-4db5-88f1-b61bdee0b002",
   "metadata": {},
   "source": [
    "先往 `DATA_HUB` 里加入数据集链接和 `sha1` 加密码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c48b2fa-bee5-462e-bb5f-2dfc23c9fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUB['kaggle_house_train'] = (DATA_URL + 'kaggle_house_pred_train.csv', '585e9cc93e70b39160e7921475f9bcd7d31219ce')\n",
    "\n",
    "DATA_HUB['kaggle_house_test'] = (DATA_URL + 'kaggle_house_pred_test.csv', 'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3dd220-9758-41bd-ab07-8267dc0ecf52",
   "metadata": {},
   "source": [
    "使用 `pandas` 读数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6525fe39-336d-44de-ba1b-41d6e47ccc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载.\\data\\house\\kaggle_house_pred_train.csv\n",
      "从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载.\\data\\house\\kaggle_house_pred_test.csv\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(download('kaggle_house_train'))\n",
    "test_data = pd.read_csv(download('kaggle_house_test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9514b3d-9c11-4494-acea-cd88d3018c97",
   "metadata": {},
   "source": [
    "训练数据集多出来的一个维度是标签（salePrice）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03595cc6-867e-4a23-b769-bcdfa93fa2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b0740-b11a-4037-a37f-e1e722959f1c",
   "metadata": {},
   "source": [
    "查看一些特征和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a345ba0-ab6e-4d15-a4e1-68d0fd76b43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
       "0   1          60       RL         65.0       WD        Normal     208500\n",
       "1   2          20       RL         80.0       WD        Normal     181500\n",
       "2   3          60       RL         68.0       WD        Normal     223500\n",
       "3   4          70       RL         60.0       WD       Abnorml     140000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[:4, [0, 1, 2, 3, -3, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c716e-634a-4dc8-b74a-c90ea3710e6e",
   "metadata": {},
   "source": [
    "我们将删除 `id`，因为其不参与训练，而且会对训练产生影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f2832be-a91c-487e-a3d5-3bffb9c62b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e06b02-5e1e-4a90-97b6-65cdd86d3f46",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb484896-b3b8-4a5d-8f74-694b9f78f7db",
   "metadata": {},
   "source": [
    "首先将所有数值型特征标准化为标准正态分布，这么做是为了在初始化特征系数（w）的时候，由于不知道哪些特征是和结果相关的不偏袒任何一个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e9bacd7-ed4d-40a5-a583-dfa887d237b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index # 找出所有数值型的特征\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(lambda x : (x - x.mean()) / (x.std())) # 化为标准正态分布\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0) # NA填0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6db900-3e24-4d62-8a1b-c18dc617becf",
   "metadata": {},
   "source": [
    "将字符型的特征变为 `one-hot` 编码，比如 `MSZoning` 有 `RL` 和 `RM` 和 `NA` 三种类型，那就会变成三种特征：`MSZoning_RL/RM/NA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "45bc1cb3-5903-4f39-9a2e-d965737034dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.get_dummies(all_features, dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbed72-31bc-4f63-a5b5-6c1c36f345df",
   "metadata": {},
   "source": [
    "从 `pandas` 格式中提取 `numpy` 格式并转化为张量用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb68a6c4-6810-4355-abe4-137dd839e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values.astype(float), dtype=torch.float32) # 这里转换有问题，要先把 object 强转为 float\n",
    "test_features = torch.tensor(all_features[n_train:].values.astype(float), dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_data.iloc[:, -1].values.astype(float).reshape(-1, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387445ce-c0c6-463c-b7fb-8ddae6bffb34",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "28bbee5b-a937-4780-af2b-938ee088d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "in_features = train_features.shape[1]\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(in_features, 1))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de20ce-4c1c-4182-8dcd-1ee60a6d7fe5",
   "metadata": {},
   "source": [
    "房价预测更关心相对损失，而不是绝对损失，比如预测结果偏差10w，对于房价400w的房子预测的好，而对于房价20w的房子就不行，相对误差是 $\\frac {y - \\hat {y}} y$，于是误差指标应该是 $|log(\\hat {y}) - log(y)|$（经过一系列变换，让除法变减法），再应用均方误差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77dda48-fa8d-46fa-855e-edd90017b3fc",
   "metadata": {},
   "source": [
    "这里的 `log_rmse` 函数是在一次迭代训练之后（使用原始loss）使用，以查看每次训练后模型的误差情况，说白了训练还是使用均方误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dd723486-60d1-422f-8184-c763dba8382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_rmse(net, features, labels):\n",
    "    clipped_preds = torch.clamp(net(features), 1, float('inf')) # 将预测值小于 1 的部分裁剪到 [1, 正无穷]，对数就不用处理小于 0 的部分了\n",
    "    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels))) # 损失函数\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bbadbf-3517-4227-864d-89923197f0a3",
   "metadata": {},
   "source": [
    "训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca9fa94c-8c5a-4471-8373-1f587781dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, test_featrues, \n",
    "          test_labels, num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], [] # 相对误差\n",
    "    updater = torch.optim.Adam(net.parameters(), lr, weight_decay=weight_decay) # 类似SGD\n",
    "    train_iter = d2l.load_array((train_features, train_labels), batch_size)\n",
    "    for epoch in num_epochs:\n",
    "        for X, y in train_iter:\n",
    "            updater.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            updater.step()\n",
    "        train_ls.append(log_rmse(net, train_features, train_labels)) # 训练相对误差\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(net, test_featrues, test_labels)) # 验证相对误差\n",
    "    return train_ls, test_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa471db-82a9-4791-81c1-4bd4d6fd2d2c",
   "metadata": {},
   "source": [
    "使用K折交叉验证，`get_k_fold_data` 函数用于返回第 i 折作为验证数据，其他作为训练数据，注意，这个函数只是返回一次迭代的训练和验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2c537f1e-59c3-4b66-88e6-ba324282cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k # 每一折包含的样本数\n",
    "    X_train, y_train = None, None # 初始化训练集\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size) # 这一折的索引，写一下就知道是一个区间\n",
    "        X_part, y_part = X[idx, :], y[idx] # 根据索引拿出这一折的数据\n",
    "        if j == i: # 第 i 折作为验证数据\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None: # 不是第 i 折就是训练数据，训练数据第一次赋值\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else: # 后续只需加入\n",
    "            X_train = torch.cat([X_train, X_part], 0) # 第 0 维度，按列拼接\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322e398-3c44-4973-ac6d-49bda06d5d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
