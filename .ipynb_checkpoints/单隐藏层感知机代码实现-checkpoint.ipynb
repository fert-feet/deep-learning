{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf316a8-5126-4ef2-ac54-9d057741b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import d2l.torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c16df4-26f4-4f5f-b7cc-6a58a891f1fc",
   "metadata": {},
   "source": [
    "设定初始 w 和 b，由于输入数据是 `256 * 784` 的矩阵，那么 `W1` 自然是 `784 * 隐藏层单元数`（这里和笔记中不一样是因为矩阵相乘的顺序不同，也仅此而已），输出层的 `W2` 是 `隐藏层单元数 * 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a839066c-223c-4598-989b-5fea8e574ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256 # 256 是隐藏层单元数\n",
    "\n",
    "W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad = True)) # 784 * 256\n",
    "b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad = True)) # 256 * 1 设为 0 \n",
    "W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad = True)) # 256 * 10\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs, num_outputs, requires_grad = True)) # 10 * 1 设为 0\n",
    "\n",
    "params = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69e955-33f8-4c98-9abc-b92edc8e8044",
   "metadata": {},
   "source": [
    "### 实现 ReLU 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84822812-3970-427c-967d-adff3608c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    a = torch.zeros_like(X)\n",
    "    return torch.max(X, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52bfc85-db88-42f7-aaae-707f5b9cb276",
   "metadata": {},
   "source": [
    "### 实现模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce10e70-510f-4192-ba02-5047d5848c45",
   "metadata": {},
   "source": [
    "隐藏层：$H = \\sigma(XW_1 + b_1)$\n",
    "\n",
    "输出层：$o = HW_2 + b_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8756b10c-cd95-4ea9-a80e-458034fa5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    X = X.reshape((-1, num_inputs))\n",
    "    H = relu(X @ W1 + b1)\n",
    "    print(H.shape)\n",
    "    return(H @ W2 + b2)\n",
    "\n",
    "loss = nn.CrossEntropyLoss() #使用交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d565f85-3e3f-486c-9f15-a7f5b4a573c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, lr = 10, 0.1\n",
    "updater = torch.optim.SGD(params, lr=lr)\n",
    "# d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater) # 有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8ccf9-c680-4b82-8b44-0dd74aa54665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
